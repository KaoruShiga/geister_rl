task:
1. 課題の全消化(試験，レポート，アメフト)
2. 初期配置の強化学習
3. 重みを手動調整して，青脱出可能にする．
4. 強さの指標の決定及び有効性の確認(総当たり戦と比較)
opt. 2駒関係の導出法の改良


今後の方針:
v6:
現状，乱数に依存しすぎている．
初期配置も強化学習すべき．あと，epsilonを減らすかわりに，初期状態の重みを指定のものにすべき．
これで95%以上の勝率を確認したい．
じゃなきゃ先に進めない．

結局，脱出を学習できたら95%以上になって，脱出を学習できなきゃ80~90くらいになる．
脱出を先に学習できるかは運．初期配置ランダムだと特に学習ができてない．
ここを解決するために...手動での重み実装が考えられる．
そしてepsilonを減らそう!!!ついでに初期配置も強化学習の対象にしよう．

対戦相手をランダムに限定すれば，つまりMDPならば適切に収束することを確認しよう
そしてその後，クラスター学習&クラスター間での比較を考えよう．
さすがにその状況ならmc法の方が有利なはず...

v5:
やることも多いので，もうしばらくはpythonでやる．
ロジスティック回帰は分類問題のためのもので回帰には使わないらしいけど，使った方が良いのかも
L1正則化を使えば有効性を確認できる可能性がある．
3駒関係は処理速度とメモリ量に不安があるので，暫定的に見送り決定．

逆に2駒関係の有用性はひとまず確認ずみ．(?)
学習後の重みを使ってランダム相手の勝率を引き上げれば，
単純な線形関数近似との比較が鮮明になるだろう．
むしろ，95%を達成したときは設定済みの重みから始めたので，
脱出をする方向性を考えさせた方がよいと思う．
つまり...optimistic初期値!!!!
重みの初期値が0より少し(割と)大きければよい．
->結果: 大成功(パラメタ調整は必要だった)
限界突破も確認できた．
ということで...2駒関係の有用性はok．

mc法が優れていることは，ランダム以外の対戦相手と戦って確認する予定．



v4:
工房のgeister.pyに移行．ランダムプレイヤでも十秒で一万局やれる．(速い)
tdagentの動作確認．
次にやるのは三駒td，三駒mcの実装と効果の確認．
その後，三駒mc+例のアレをやる．

大会前に通信テストを行いたい．

v3:
get_after_statesにバグを発見．
  test_tdで時間がかかりすぎるのはバグっぽい
  とりあえずテスト増やそう...
やはり，先生のやつも使ってみてその後に検討かなぁ．
ただC言語だと...MCはキュー使うし...afterstatesは可変長だし...
  ->MCはキュー使え，afterstatesは固定長配列の一部を使え
      (afterstateの最大数=最大有効候補手，は決まってる．8*4)
とは言え，C言語はキツイから，線形近似くらいは使っとこう．


v2:
ガイスター初回の内容にもよるが，boardの軽量化の後，線形強化学習，三駒が望ましい．
ただこれくらいの内容ならC言語でもなんとかなる気はする．
(内積は配列でやって良さそうな大きさだし，三ゴマ関係はどうせ実装必須)

まず，遅すぎる．boardの仕様が原因だと考えられる．
正直，ランダムな相手どころかpassAgentに対してさえ学習できそうにない．
現状，一秒あたり1000ターンしかできない．
最後の一手が偶然起こるのを待つのに0.2s程かかる(学習は無謀)
まぁ，先生のやつ使うのが前提かなぁ...
とは言え，線形近似くらいは使用経験がないときつそうなので，
初期状態をなんか作っておいてそこから学習させましょうか．

->時間がかかりすぎるのはバグっぽい

v1:
まずランダムな固定相手に対して線形関数近似で強化学習させる．
仕様上，常に先攻であるとする
有用性を確認できるはず

boardの仕様変更(orプラットフォームの移行orAgent側で対応)により，
後攻でも対応できるようにする．
具体的には後攻のプレイヤーにデータを渡すときともらうときに盤面の反転を行う
