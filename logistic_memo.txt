v2:
https://tadaoyamaoka.hatenablog.com/entry/2017/04/02/235014
ボナンザはロジスティック関数を使っていた．という話...
あとL1正則化も使ってたらしいよ．
重みが大量にあるから，案外L1正則化が有力なのかも
0.9付近では有力な可能性があるから，確認してみよう!



v1.
なぜかわからなかったが，強化学習においてロジスティック回帰を用いる方法は見かけない．
そして，実際にやってみてもなぜか線形関数近似の方が良い性能を出す．

一方で，将棋の評価関数の値は無限大から負の無限大までを取り，なんか，ロジスティック回帰っぽい．
どうやってるんやろう?
そっちの方が最終的な精度は良さそう．
重みの更新方法について調査する必要性もあるかもね...



ともかく，
ロジスティック関数を活性化関数っぽく使ってみたが
線形関数近似に劣る性能しか出せていない．
ロジスティック関数をはめてみるだけというのは効果がなさそう．
